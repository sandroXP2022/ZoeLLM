# utils/preprocess.py

import os
import json
import re
from pathlib import Path
from tqdm import tqdm

DATASETS_DIR = Path(__file__).resolve().parent.parent / "datasets"
MERGED_FILE = DATASETS_DIR / "unprocessed_data.jsonl"
FINAL_FILE = DATASETS_DIR / "dataset.jsonl"

MERGED_FILE.parent.mkdir(parents=True, exist_ok=True)

CODE_PATTERNS = [
    r"```[\s\S]*?```",             # Bloco inteiro de c√≥digo markdown
    r"\bdef\s+\w+\s*\(",           # Fun√ß√µes Python (mais preciso)
    r"\bclass\s+\w+\s*[:{]",       # Classes Python/C++
    r"\bimport\s+[\w.]+",          # Importa√ß√µes Python mais amplas
    r"#include\s+<[^>]+>",         # Include C/C++
    r"[a-zA-Z_]\w*\s*=\s*[^;]+;",  # Atribui√ß√£o em linguagens como JS/Java
    r"\bfunction\s+\w*\s*\(",      # Fun√ß√µes em JS
    r"^\s{4,}",                    # Indenta√ß√£o t√≠pica de c√≥digo
    r"</?[a-zA-Z0-9]+[^>]*?>",     # Tags HTML com atributos opcionais
    r"\bvar\s+\w+\b",              # Declara√ß√£o de vari√°vel em JS
    r"\bconsole\.log\(",           # Log JS
    r"\bSystem\.out\.print"        # Java
]

CONV_PATTERNS = [
    r"^(User|Assistant|Usu√°rio|Assistente):",   # Identificadores de fala
    r"\b(pergunta|resposta|question|answer)\s*:",  # R√≥tulos de QA
    r"(?i)^\s*(q|a)\s*[:\-]",                  # Q: ou A: com varia√ß√µes
    r"\?\s*(?:$|\n)",                          # Pergunta no final da frase
    r"(voc√™|tu|meu|sua|nosso|teu)\b",          # Pronomes t√≠picos de conversa
    r"\b(o que|como|quando|por que|quem|onde)\b",  # Perguntas
    r"^[-*]?\s*(Sim|N√£o|Talvez)\b",            # Respostas diretas
    r"\b(chatgpt|gpt|modelo|responda)\b"       # Men√ß√£o √† IA
]

INSTR_PATTERNS = [
    r"^\d+\.\s",                                # Lista numerada
    r"^[-*+]\s",                                # Marcadores de lista
    r"\b(passos?|etapas?|instru√ß√µes?)\b",       # Varia√ß√µes
    r"\b(tutorial|guia|manual|how to)\b",       # Termos comuns
    r"\b(abra|clique|instale|copie|crie)\b",    # Verbos imperativos
    r"\binstal(?:e|a√ß√£o|ar|ado)\b",             # Instalar variantes
    r"\b(run|execute|compile|launch|start)\b",  # Execu√ß√£o
    r"\bterminal|linha de comando\b",           # Contexto CLI
    r"\bdownload\b",                            # Download direto
    r"\bc√≥digo\s+abaixo\b",                     # Refer√™ncia a c√≥digo
    r"\bsiga\s+os\s+passos\b",                  # Frases guia
    r"\bconfigure\b",                           # Configura√ß√£o
]



# Fun√ß√£o para classificar texto
def classificar_texto(text: str) -> str:
    t = text.strip()
    if not t:
        return None
    # Densidade de s√≠mbolos de c√≥digo
    sym_count = len(re.findall(r"[{}<>;=()\[\]]", t))
    density = sym_count / max(len(t), 1)
    if density > 0.05:
        return "codigo"

    # Verifica√ß√£o por padr√µes de c√≥digo
    for pat in CODE_PATTERNS:
        if re.search(pat, t, flags=re.MULTILINE):
            return "codigo"

    # Texto conversacional
    for pat in CONV_PATTERNS:
        if re.search(pat, t, flags=re.IGNORECASE | re.MULTILINE):
            return "conversacional"

    # Texto instrucional
    for pat in INSTR_PATTERNS:
        if re.search(pat, t, flags=re.IGNORECASE):
            return "instrucional"

    # Texto informativo
    return "informativo"

# Fus√£o de Datasets
def juntar_datasets():
    files = [f for f in DATASETS_DIR.glob("*.jsonl") if f.name not in {MERGED_FILE.name, FINAL_FILE.name}]
    with MERGED_FILE.open("w", encoding="utf-8") as out:
        for file in tqdm(files, desc="üîÑ Merge files", unit="file"):
            for line in file.open("r", encoding="utf-8"):
                out.write(line)

# Classifica√ß√£o e Entrega de Dataset Final
def processar_e_classificar():
    # Contar linhas para barra de progresso
    total = sum(1 for _ in MERGED_FILE.open("r", encoding="utf-8"))
    with MERGED_FILE.open("r", encoding="utf-8") as inp, FINAL_FILE.open("w", encoding="utf-8") as out:
        for line in tqdm(inp, total=total, desc="üîç Classifying", unit="line"):
            try:
                obj = json.loads(line)
                text = obj.get("text", "").strip()
                cat = classificar_texto(text)
                if cat:
                    out.write(json.dumps({"text": text, "category": cat}, ensure_ascii=False) + "\n")
            except json.JSONDecodeError:
                continue

if __name__ == "__main__":
    print("Iniciando pr√©-processamento...")
    print("------------------------------")
    print("------------------------------")
    juntar_datasets()
    print("FUS√ÉO DE DATASETS COMPLETA")
    print(f"Dataset Completo em: {MERGED_FILE}")
    print("----------------------------------")
    processar_e_classificar()
    print("DATASET PROCESSADO")
    print(f"Dataset Final Dispon√≠vel em: {FINAL_FILE}")

